# -*- coding: utf-8 -*-
"""KNN BIKE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zfOgk2GI_PQaTOYlCVQRDgx7zrIsok8R

**Importación de librerías necesarias**
"""

from google.colab import drive
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns; 
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import accuracy_score
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

from sklearn.model_selection import KFold

from sklearn.model_selection import cross_val_score

from sklearn import datasets, metrics

"""**Preproceso**

Montar drive para la carga de datos
"""

drive.mount('/content/drive')

"""Importación de los datos del dataset"""

df = pd.read_csv("/content/drive/MyDrive/bikes.csv")

"""Mostrar las primeras y últimas filas del dataframe importado

"""

df

"""Tipos de datos del df"""

df.dtypes

"""Conversion de date(object) a date"""

df['date'] = pd.to_datetime(df['date'])

df.dtypes

"""Mostrar parámetros estadísticos de los datos (media, desviación típica, cuartiles, etc.)"""

df.describe()

"""Mostrar un mapa de calor que indique la correlación entre vriables"""

sns.set()

# para definir el tamaño de cada dato
plt.figure(figsize=(16, 8))

sns.heatmap(df.corr(),annot = True)

"""Seleccionar las características a tener en cuenta en el estudio"""

df_filtrado  = pd.DataFrame()
df_filtrado = df[['temperature','humidity','windspeed','count']].copy()
                  
df_filtrado
# df_filtrado.plot()

"""Separar datos entre datos de entrada y etiquetas (resultados)"""

# x_bike = df_filtrado.drop('count',axis = 1)
# y_bike = df_filtrado['count']

"""Separar datos entre entrenamiento y prueba (usando un 75% para entrenamiento y 25% para test)"""

# x_train,x_test,y_train,y_test = train_test_split(x_bike,y_bike,
#                                                  train_size = 0.75,
#                                                  test_size = 0.25
#                                                  )


train_bike = df_filtrado.iloc[:501]
test_bike = df_filtrado.iloc[502:]

# train
x_train = train_bike[['temperature','humidity','windspeed']]
y_train = train_bike['count']

# test
x_test = test_bike[['temperature','humidity','windspeed']]
y_test = test_bike['count']

"""**Entrenamiento y predicción**

Elegir, instanciar y entrenar el modelo
"""

# con KNeighborsRegressor
# parametros
k = 10
w = 'distance'

# elegimos clasificador

# instanciamos el modelo
model = KNeighborsRegressor(k,weights=w)

# entrenamiento
model.fit(x_train,y_train)

"""Realizar una predicción con los datos de prueba"""

# prediccion
y_model = model.predict(x_test)

y_model

"""**Evaluación**"""

# evaluacion
from sklearn.metrics import mean_squared_error
mean_squared_error = mean_squared_error(y_model,y_test)
print(f"error cuadrático medio: {mean_squared_error}")


from sklearn.metrics import mean_absolute_error
mean_absolute_error = mean_absolute_error(y_model,y_test)
print(f"error absoluto medio: {mean_absolute_error}")

"""Representar gráficamente los valores predichos con los valores reales"""

import numpy as np

 

y_pred = y_model

xx = np.stack(i for i in range(y_test.shape[0]))
plt.figure(figsize=(18,10))
plt.plot(xx, y_test, c='r', LineWidth = 2, label = 'data')
plt.plot(xx, y_pred, c='g', LineWidth = 2, label = 'prediction')
plt.axis('tight')
plt.legend()
plt.show()

"""**Optimización de hiperparámetros**

Calcula la combinación de parámetros óptima (uniform o distance; valor de k). Para ello
realiza ejecuciones con cada uno de los valores uniform y distance para los valores de k
desde 1 a 30.
"""

from pandas.core.dtypes.inference import is_file_like
# con KNeighborsRegressor

# parametros
# k = 3
# w = 'uniform'

valores_w = ['uniform','distance']
errores_absoluto = []
k_min = 0
w_min = ""

for w in valores_w:
  for k in range(1,31):
    # instanciamos el modelo
    model = KNeighborsRegressor(k,weights=w)

    # entrenamiento
    model.fit(x_train,y_train)

    # Mostrar la predicción realizada (imprimir la variable con la predicción)
    # y_model
    # print(y_model)

    y_model = model.predict(x_test)

    from sklearn.metrics import mean_absolute_error
    mean_absolute_error = mean_absolute_error(y_model,y_test)

    errores_absoluto.append(mean_absolute_error)

    if min(errores_absoluto) == mean_absolute_error:
      k_min = k
      w_min = w

    from sklearn.metrics import mean_absolute_error
    print(f"mean_absolute_error: {mean_absolute_error(y_test,y_model)} con k como: {k} y con w como: {w}")

print(f"El valor min de error absoluto es:{min(errores_absoluto)}, con k={k_min}, y w={w_min}")

"""Usando los mejores parametros"""

# con KNeighborsRegressor
# parametros
k = k_min
w = w_min

# elegimos clasificador

# instanciamos el modelo
model = KNeighborsRegressor(k,weights=w)

# entrenamiento
model.fit(x_train,y_train)

# prediccion
y_model = model.predict(x_test)

# evaluacion
from sklearn.metrics import mean_squared_error
mean_squared_error = mean_squared_error(y_model,y_test)
print(f"error cuadrático medio: {mean_squared_error}")


from sklearn.metrics import mean_absolute_error
mean_absolute_error = mean_absolute_error(y_model,y_test)
print(f"error absoluto medio: {mean_absolute_error}")

y_pred = y_model

xx = np.stack(i for i in range(y_test.shape[0]))
plt.figure(figsize=(18,10))
plt.plot(xx, y_test, c='r', LineWidth = 2, label = 'data')
plt.plot(xx, y_pred, c='g', LineWidth = 2, label = 'prediction')
plt.axis('tight')
plt.legend()
plt.show()