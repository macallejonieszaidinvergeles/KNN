# -*- coding: utf-8 -*-
"""KNN WINE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-oSyTB4WGjotw1QomBLs_U30GlYJJ1D6

**Importación de librerías necesarias**
"""

from google.colab import drive
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns; 
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neighbors import RadiusNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

from sklearn.model_selection import KFold

from sklearn.model_selection import cross_val_score

from sklearn import datasets, metrics

"""**Preproceso**

Montar drive para la carga de datos
"""

drive.mount('/content/drive')

"""Importación de los datos del dataset"""

df = pd.read_csv("/content/drive/MyDrive/WineQT.csv")

"""Mostrar las primeras y últimas filas del dataframe importado

"""

df

"""Tipos de datos del df"""

df.dtypes

"""Mostrar parámetros estadísticos de los datos (media, desviación típica, cuartiles, etc.)"""

df.describe()

"""Mostrar un mapa de calor que indique la correlación entre vriables"""

sns.set()

# para definir el tamaño de cada dato
plt.figure(figsize=(16, 8))

sns.heatmap(df.corr(),annot = True)

"""Seleccionar las características a tener en cuenta en el estudio"""

# campos : fixed acidity	,citric acid,residual sugar , density	, pH,sulphates,alcohol,
# quality

df_filtrado  = pd.DataFrame()
df_filtrado = df[['fixed acidity', 'citric acid','residual sugar','density',
                  'pH','sulphates','alcohol','quality']].copy()
                  
df_filtrado
# df_filtrado.plot()

"""Separar datos entre datos de entrada y etiquetas (resultados)"""

x_wine = df_filtrado.drop('quality',axis = 1)
y_wine = df_filtrado['quality']

"""Separar datos entre entrenamiento y prueba (usando un 75% para entrenamiento y 25% para test)"""

x_train,x_test,y_train,y_test = train_test_split(x_wine,y_wine,
                                                 train_size = 0.75,
                                                 test_size = 0.25
                                                 )

"""**Entrenamiento y predicción**

Elegir, instanciar y entrenar el modelo
"""

# con KNeighborsClassifier

# parametros
k = 3
w = 'uniform'

# elegimos clasificador

# instanciamos el modelo
model = KNeighborsClassifier(k,weights=w)

# entrenamiento
model.fit(x_train,y_train)

"""Realizar una predicción con los datos de prueba"""

# prediccion
y_model = model.predict(x_test)

"""**Evaluación**

Mostrar el porcentaje de elementos correctamente clasificados
"""

# evaluacion

# Mostrar el porcentaje de elementos correctamente clasificados
accuracy_score(y_test,y_model)

"""Mostrar la predicción realizada (imprimir la variable con la predicción)

"""

y_model

"""Representar gráficamente la clasificación obtenida (matriz de confusión)

"""

cm = confusion_matrix(y_test, y_model, labels=model.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=model.classes_)
disp.plot()

plt.show()

"""**Optimización (probar el proceso con distintos clasificadores)**

**METODO DE RadiusNeighborsClassifier**
"""

# instanciamos el modelo
model = RadiusNeighborsClassifier(radius = 2)


# entrenamiento
model.fit(x_train,y_train)

# prediccion
y_model = model.predict(x_test)

# predict_proba([[1.0]]))


# evaluacion
# Mostrar el porcentaje de elementos correctamente clasificados
accuracy_score(y_test,y_model)

# Mostrar la predicción realizada (imprimir la variable con la predicción)
y_model

# Representar gráficamente la clasificación obtenida (matriz de confusión)
cm = confusion_matrix(y_test, y_model, labels=model.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=model.classes_)
disp.plot()

plt.show()

"""con KNeighborsClassifier se obtiene un 55% mientras que con RadiusNeighborsClassifier se obtiene un 52%. Respectivamente, en las matrices de confusion vemos una gran diferencia, mientras que en el primero el valor max es 82, en el otro el valor max es 106, y con el min, seria de 64 y 41.

**Optimización de hiperparámetros**

Calcula la combinación de parámetros óptima (uniform o distance; valor de k). Para ello
realiza ejecuciones con cada uno de los valores uniform y distance para los valores de k
desde 1 a 30.
"""

from pandas.core.dtypes.inference import is_file_like
# con KNeighborsClassifier

# parametros
# k = 3
# w = 'uniform'

valores_w = ['uniform','distance']
porcentajes = []
k_max = 0
w_max = ""

for w in valores_w:
  for k in range(1,31):
    # instanciamos el modelo
    model = KNeighborsClassifier(k,weights=w)

    # entrenamiento
    model.fit(x_train,y_train)

    # Mostrar la predicción realizada (imprimir la variable con la predicción)
    # y_model
    # print(y_model)

    y_model = model.predict(x_test)

    porcentajes.append(accuracy_score(y_test,y_model))

    if max(porcentajes) == accuracy_score(y_test,y_model):
      k_max = k
      w_max = w


    print(f"El porcentaje: {accuracy_score(y_test,y_model)} con k como: {k} y con w como: {w}")

print(f"El valor max de porcentaje es:{max(porcentajes)}, con k={k_max}, y w={w_max}")

"""Cada ejecución anterior se deberá hacer usando validación cruzada (por ejemplo n_splits =
5). Con ello obtendremos una medida de bondad del modelo (accuracy_score o
mean_absolute_error)), como lo ejecutaremos 5 veces, calcularemos la media de esas 5
ejecuciones.

"""

kf = KFold(n_splits=5)
 
# parametros
k = k_max
w = w_max

# elegimos clasificador

# instanciamos el modelo
model = KNeighborsClassifier(k,weights=w)

# entrenamiento
model.fit(x_train,y_train)
 
score = model.score(x_train,y_train)
 
print("Metrica del modelo", score)
 
scores = cross_val_score(model, x_train, y_train, cv=kf, scoring="accuracy")
 
print("Metricas cross_validation", scores)
 
print("Media de cross_validation", scores.mean())
 
preds = model.predict(x_test)
 
score_pred = metrics.accuracy_score(y_test, preds)

print("Metrica en Test", score_pred)

# evaluacion
# Mostrar el porcentaje de elementos correctamente clasificados
accuracy_score(y_test,y_model)

# Mostrar la predicción realizada (imprimir la variable con la predicción)
y_model

cm = confusion_matrix(y_test, y_model, labels=model.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=model.classes_)
disp.plot()

plt.show()