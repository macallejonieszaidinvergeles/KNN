# -*- coding: utf-8 -*-
"""KNN Heart.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ij3vIIsqLj2UOcCPptFEA5_cEW_JU4y4

**Importación de librerías necesarias**
"""

from google.colab import drive
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns; 
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import BernoulliNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

from sklearn.model_selection import KFold

from sklearn.model_selection import cross_val_score

from sklearn import datasets, metrics

"""**Preproceso**

Montar drive para la carga de datos
"""

drive.mount('/content/drive')

"""Importación de los datos del dataset"""

df = pd.read_csv("/content/drive/MyDrive/heart.csv")

"""Mostrar las primeras y últimas filas del dataframe importado

"""

df

"""Tipos de datos del df"""

df.dtypes

"""Mostrar parámetros estadísticos de los datos (media, desviación típica, cuartiles, etc.)"""

df.describe()

"""Mostrar un mapa de calor que indique la correlación entre vriables"""

sns.set()

# para definir el tamaño de cada dato
plt.figure(figsize=(16, 8))

sns.heatmap(df.corr(),annot = True)

"""Seleccionar las características a tener en cuenta en el estudio"""

# campos : por ahora sin filtar

# df_filtrado  = pd.DataFrame()
# df_filtrado = df[[]].copy()

# df_filtrado

"""Separar datos entre datos de entrada y etiquetas (resultados)"""

x_heart = df.drop('target',axis = 1)
y_heart = df['target']

"""Separar datos entre entrenamiento y prueba (usando un 75% para entrenamiento y 25% para test),  separacion train y test"""

x_train,x_test,y_train,y_test = train_test_split(x_heart,y_heart,
                                                 test_size = 0.25,
                                                 train_size = 0.75)

"""**Entrenamiento y predicción**

Elegir, instanciar y entrenar el modelo
"""

model = BernoulliNB()

# entrenamiento
model.fit(x_train,y_train)

"""Realizar una predicción con los datos de prueba"""

# prediccion
y_model = model.predict(x_test)

"""**Evaluación**

Mostrar el porcentaje de elementos correctamente clasificados
"""

# evaluacion
accuracy_score(y_test,y_model)

"""Mostrar la predicción realizada (imprimir la variable con la predicción)

"""

y_model

"""Representar gráficamente la clasificación obtenida (matriz de confusión)

"""

cm = confusion_matrix(y_test, y_model, labels=model.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=model.classes_)
disp.plot()

plt.show()

"""**Optimización de hiperparámetros**

Calcula la combinación de parámetros óptima (uniform o distance; valor de k). Para ello realiza ejecuciones con cada uno de los valores uniform y distance para los valores de k desde 1 a 30.
"""

from pandas.core.dtypes.inference import is_file_like
# con KNeighborsClassifier

# parametros
# k = 3
# w = 'uniform'

valores_w = ['uniform','distance']
porcentajes = []
k_max = 0
w_max = ""

for w in valores_w:
  for k in range(1,31):
    # instanciamos el modelo
    model = KNeighborsClassifier(k,weights=w)

    # entrenamiento
    model.fit(x_train,y_train)

    # Mostrar la predicción realizada (imprimir la variable con la predicción)
    # y_model
    # print(y_model)

    y_model = model.predict(x_test)

    porcentajes.append(accuracy_score(y_test,y_model))

    if max(porcentajes) == accuracy_score(y_test,y_model):
      k_max = k
      w_max = w


    print(f"El porcentaje: {accuracy_score(y_test,y_model)} con k como: {k} y con w como: {w}")

print(f"El valor max de porcentaje es:{max(porcentajes)}, con k={k_max}, y w={w_max}")

"""Cada ejecución anterior se deberá hacer usando validación cruzada (por ejemplo n_splits =
5). Con ello obtendremos una medida de bondad del modelo (accuracy_score o
mean_absolute_error)), como lo ejecutaremos 5 veces, calcularemos la media de esas 5
ejecuciones.

"""

kf = KFold(n_splits=5)
 
# parametros
k = k_max
w = w_max

# elegimos clasificador

# instanciamos el modelo
model = KNeighborsClassifier(k,weights=w)

# entrenamiento
model.fit(x_train,y_train)
 
score = model.score(x_train,y_train)
 
print("Metrica del modelo", score)
 
scores = cross_val_score(model, x_train, y_train, cv=kf, scoring="accuracy")
 
print("Metricas cross_validation", scores)
 
print("Media de cross_validation", scores.mean())
 
preds = model.predict(x_test)
 
score_pred = metrics.accuracy_score(y_test, preds)

print("Metrica en Test", score_pred)

# evaluacion
# Mostrar el porcentaje de elementos correctamente clasificados
accuracy_score(y_test,y_model)

# Mostrar la predicción realizada (imprimir la variable con la predicción)
y_model

cm = confusion_matrix(y_test, y_model, labels=model.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=model.classes_)
disp.plot()

plt.show()